{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "O objetivo do exercício é praticar a codificação utilizando o Tensorflow e aplicar o mesmo nos conceitos apresentados em aula.\n",
    "\n",
    "Neste exercício, utilizaremos um dataset bem conhecido: o dataset de dígitos escritos a mão do MNIST. Este dataset consiste em 60.000 imagens, de tamanho 28x28, dos dígitos de 0 a 9, escritos à mão. \n",
    "\n",
    "Devem ser criadas duas redes neurais capazes de classificar estas imagens: uma Rede Neural convencional (MLP), contendo duas camadas ocultas de 256 neurônios cada (ou qualquer valor que queira) e uma camada de saída. Algo semelhante à figura abaixo:\n",
    "\n",
    "![Image](http://cs231n.github.io/assets/nn1/neural_net2.jpeg)\n",
    "\n",
    "A segunda rede a ser codificada deve ser uma Rede Neural Convolucional (CNN) contendo ao menos duas camadas de convolução, duas camadas de pooling e uma camada fully-connected.\n",
    "\n",
    "![Image](https://www.mdpi.com/entropy/entropy-19-00242/article_deploy/html/images/entropy-19-00242-g001.png)\n",
    "\n",
    "Ao final da implementação de ambas, a acurácia das redes deve ser apresentada para verificação de qual rede se saiu melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "##############################\n",
      "x_test: (10000, 784)\n",
      "y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Carregando o dataset a ser trabalhado, e separando o mesmo em variáveis\n",
    "\n",
    "mnist = input_data.read_data_sets('mnist/', one_hot=True)\n",
    "\n",
    "training_set = mnist.train\n",
    "\n",
    "x_train, y_train = mnist.train.images, mnist.train.labels\n",
    "x_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "\n",
    "x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "\n",
    "print('##############################')\n",
    "print('x_test: {}'.format(x_test.shape))\n",
    "print('y_test: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros utilizados pela rede neural inicial\n",
    "# Caso queira, estes parâmetros podem ser modificados, com exceção do n_input e n_output\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "n_input = 784 # O tamanho de cada imagem do dataset MNIST é 28x28\n",
    "n_output = 10 # 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para criação das variáveis referentes aos pesos e bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo. O modelo deve conter três camadas além da camada de entrada,\n",
    "# duas camadas ocultas de N neurônios cada, e uma camada de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para definição da função de custo e validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização das variáveis do tensorflow\n",
    "start = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do modelo\n",
    "with tf.Session() as sess:\n",
    "    sess.run(start)\n",
    "    \n",
    "    # SEU CÓDIGO VIRÁ AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetando o grafo de execução do Tensorflow para construção da CNN\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros utilizados pela rede neural convolucional\n",
    "# Caso queira, estes parâmetros podem ser modificados, com exceção do n_input e n_output\n",
    "\n",
    "learning_rate = 0.01\n",
    "dropout = 0.75 # Valor de dropout\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "n_input = 784 # O tamanho de cada imagem do dataset MNIST é 28x28\n",
    "n_output = 10 # 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para criação das variáveis referentes aos pesos e bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para declaração da camada de convolução do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para declaração da camada de pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo. O modelo deve conter ao menos duas camadas de convolução,\n",
    "# duas camadas de pooling e uma camada fully-connected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para definição da função de custo e validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização das variáveis do tensorflow\n",
    "start = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do modelo\n",
    "with tf.Session() as sess:\n",
    "    sess.run(start)\n",
    "    \n",
    "    # SEU CÓDIGO VIRÁ AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetando o grafo de execução do Tensorflow para construção da CNN\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APRESENTAR AO FINAL A ACURÁCIA OBTIDA NOS DOIS MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_val = x_val.reshape(-1, 28,28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 6s 112us/step - loss: 0.2704 - acc: 0.9221\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 6s 104us/step - loss: 0.0980 - acc: 0.9704\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 6s 105us/step - loss: 0.0634 - acc: 0.9802\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 6s 105us/step - loss: 0.0459 - acc: 0.9853\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 6s 105us/step - loss: 0.0341 - acc: 0.9888\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 6s 106us/step - loss: 0.0263 - acc: 0.9910\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 6s 105us/step - loss: 0.0198 - acc: 0.9935\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 6s 105us/step - loss: 0.0176 - acc: 0.9942\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 6s 112us/step - loss: 0.0148 - acc: 0.9951\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 6s 112us/step - loss: 0.0122 - acc: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3706c11978>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 109us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07888378442808752, 0.9808]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential()\n",
    "model2.add(keras.layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(28,28, 1)))\n",
    "model2.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model2.add(keras.layers.Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model2.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model2.add(keras.layers.Flatten())\n",
    "model2.add(keras.layers.Dense(1000, activation='relu'))\n",
    "model2.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 61s 1ms/step - loss: 0.1640 - acc: 0.9506\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 61s 1ms/step - loss: 0.0427 - acc: 0.9868\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 61s 1ms/step - loss: 0.0279 - acc: 0.9909\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 62s 1ms/step - loss: 0.0209 - acc: 0.9934\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 62s 1ms/step - loss: 0.0148 - acc: 0.9952\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 64s 1ms/step - loss: 0.0130 - acc: 0.9957\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 60s 1ms/step - loss: 0.0119 - acc: 0.9962\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 60s 1ms/step - loss: 0.0100 - acc: 0.9967\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 60s 1ms/step - loss: 0.0090 - acc: 0.9969\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 60s 1ms/step - loss: 0.0064 - acc: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f370613c0b8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 3s 631us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.033238615538387785, 0.9908]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
